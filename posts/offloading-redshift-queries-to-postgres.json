{"id": "offloading-redshift-queries-to-postgres", "title": "Offloading subsecond Redshift queries to Postgres", "category": "Data Pipelines", "status": "draft", "preview": "At Gamesight we rely heavily on AWS Redshift to perform the in-database transformations\n  and aggregations for the ELT pipeline that power our real-time analytics. Redshift\u2019s massively\n  parallel architecture is very well suited for this workload and gives us great performance\n  when transforming large amounts of data. Unfortunately, once we have our data summarized\n  we need to be able to expose those metrics to our end users, and this is where Redshift\n  begins to struggle.", "created_at": "2019-06-27 05:01:00", "body": "<blockquote>\n  <p>This article is also available through the Gamesight engineering blog <a href=\"https://blog.gamesight.io\">here</a></p>\n</blockquote>\n\n<p>At Gamesight we rely heavily on AWS Redshift to perform the in-database transformations\nand aggregations for the ELT pipeline that power our real-time analytics. Redshift\u2019s massively\nparallel architecture is very well suited for this workload and gives us great performance\nwhen transforming large amounts of data. Unfortunately, once we have our data summarized\nwe need to be able to expose those metrics to our end users, and this is where Redshift\nbegins to struggle.</p>\n\n<p>While most of the data processing to this point has been doing operations on large\ndatasets, the queries that power our interface tend to only pull a handful of records\nat a time. The tradeoffs made in Redshift to enable its performance when scanning\nterabytes of data make it a truly terrible as a platform for large volumes of highly\nselective queries with minimal aggregation.</p>\n\n<p>In our early prototyping we found that some simple operations such as looking up\nrecords by ID from our Redshift cluster could take upwards of 5 seconds under moderate\nload. Below you can see the latency distribution of 10,000 simple lookups by ID against\na Redshift table of approximately XM rows.</p>\n\n<p>ADD DIAGRAM HERE</p>\n\n<p>We need to find a data storage solution for our reporting data into that would\nbe able to handle the query workload from our application. Luckily for us, there\nis a wonderful article on the AWS blog about solving this exact problem using Postgres\nand an extension called dblink. This solution creates a connection between Postgres and\nRedshift allowing you to easily move data directly between the two systems, a sort of\n\u201cbest of both worlds\u201d solution.</p>\n\n<p>Before we dive into the details, let\u2019s do a quick comparison of the architecture\nof Postgres and Redshift.</p>\n\n<h4 id=\"architecture-comparison\">Architecture Comparison</h4>\n\n<h4 id=\"solution-details\">Solution Details</h4>\n\n<h4 id=\"some-benchmarks\">Some Benchmarks</h4>\n\n<p>Future Work\n- Search indexes\n- Specialized stores\n- Time series data\n- Focus on having a single source of truth and various derivative data storage solutions depending on the application\u2019s needs. Redshift is great at being that source of truth for us.</p>\n\n<ul>\n<li>Motivation\n<ul>\n<li>Redshift compute is valuable</li>\n<li>Redshift is bad at handling individual or small batch record selection, especially lookups by id</li>\n<li>Overhead on compilation can be devastating for small amounts of data</li>\n</ul></li>\n<li>Solution\n<ul>\n<li>Use DBlink to sync records that are frequently accessed for non-analytical use</li>\n<li>Provides indexes and single ms response times event on large tables</li>\n<li>Keep consistent query syntax between two different data sources (generally, minus some functions) to reduce complexity when switching/doing fallbacks (opposed to a pure cache or a nosql solution). Less expensive due to large amount of regular data transfer</li>\n</ul></li>\n<li>Future work\n<ul>\n<li>Keeping small amounts of data in postgres, setup a view, fallback to redshift when not in postgres, fallback to spectrum when not in either! Maybe this should be an entirely different post</li>\n</ul></li>\n</ul>\n"}